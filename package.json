{
  "name": "vscode-git-commit-message-generator",
  "displayName": "Git Commit Message Generator",
  "description": "Making Git commits smarter and more efficient.",
  "version": "0.1.6",
  "publisher": "chenkai2",
  "author": {
    "name": "klaveriuzent",
    "url": "https://github.com/klaveriuzent"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/klaveriuzent/vscode-git-commit-generator.git"
  },
  "keywords": [
    "git",
    "commit",
    "message",
    "generator",
    "ai",
    "llm",
    "ollama",
    "openai"
  ],
  "engines": {
    "vscode": "^1.57.0"
  },
  "categories": [
    "SCM Providers",
    "Other"
  ],
  "icon": "media/panda-avatar.png",
  "activationEvents": [
    "onCommand:vscode-git-commit-message-generator.generateCommitMessage"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "vscode-git-commit-message-generator.generateCommitMessage",
        "title": "Generate Commit Message",
        "icon": {
          "dark": "media/commit-message-generator-dark.svg",
          "light": "media/commit-message-generator-light.svg"
        }
      }
    ],
    "menus": {
      "scm/title": [
        {
          "when": "scmProvider == git",
          "command": "vscode-git-commit-message-generator.generateCommitMessage",
          "group": "navigation",
          "order": 1
        }
      ]
    },
    "configuration": {
      "title": "Git Commit Message Generator",
      "properties": {
        "vscode-git-commit-message-generator.llm.provider": {
          "type": "string",
          "enum": [
            "aliyun",
            "openai",
            "ollama",
            "deepseek",
            "anthropic",
            "tencent",
            "siliconflow",
            "volcengine",
            "custom"
          ],
          "enumDescriptions": [
            "Alibaba Bailian",
            "OpenAI",
            "Ollama (local deployment)",
            "DeepSeek",
            "Anthropic Claude",
            "Tencent Hunyuan",
            "SiliconFlow",
            "Volcengine",
            "Custom configuration"
          ],
          "default": "custom",
          "description": "Choose LLM service provider"
        },
        "vscode-git-commit-message-generator.providers.aliyun.url": {
          "type": "string",
          "default": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
          "description": "Alibaba Bailian API URL"
        },
        "vscode-git-commit-message-generator.providers.aliyun.model": {
          "type": "string",
          "enum": [
            "Moonshot-Kimi-K2-Instruct",
            "deepseek-r1",
            "deepseek-r1-distill-llama-70b",
            "deepseek-v3.1",
            "deepseek-v3.2",
            "deepseek-v3.2-exp",
            "glm-4.5",
            "glm-4.5-air",
            "gui-plus",
            "kimi-k2-thinking",
            "llama-4-maverick-17b-128e-instruct",
            "llama-4-scout-17b-16e-instruct",
            "qwen-flash",
            "qwen-flash-2025-07-28",
            "qwen-long",
            "qwen-max",
            "qwen-mt-flash",
            "qwen-mt-lite",
            "qwen-mt-plus",
            "qwen-mt-turbo",
            "qwen-plus-2025-07-14",
            "qwen-plus-2025-07-28",
            "qwen-plus-2025-12-01",
            "qwen-turbo-2025-02-11",
            "qwen-turbo-2025-07-15",
            "qwen-vl-max-2025-08-13",
            "qwen-vl-ocr-2025-08-28",
            "qwen-vl-ocr-2025-11-20",
            "qwen-vl-plus-2025-08-15",
            "qwen2.5-0.5b-instruct",
            "qwen2.5-1.5b-instruct",
            "qwen3-235b-a22b-instruct-2507",
            "qwen3-235b-a22b-thinking-2507",
            "qwen3-30b-a3b-instruct-2507",
            "qwen3-30b-a3b-thinking-2507",
            "qwen3-coder-30b-a3b-instruct",
            "qwen3-coder-480b-a35b-instruct",
            "qwen3-coder-flash",
            "qwen3-coder-flash-2025-07-28",
            "qwen3-coder-plus",
            "qwen3-coder-plus-2025-07-22",
            "qwen3-max-preview",
            "qwen3-vl-30b-a3b-instruct",
            "qwen3-vl-30b-a3b-thinking",
            "qwen3-vl-8b-instruct",
            "qwen3-vl-8b-thinking",
            "qwen3-vl-flash",
            "qwen3-vl-flash-2025-10-15",
            "qwen3-vl-plus-2025-12-19",
            "qwq-plus"
          ],
          "default": "deepseek-v3.2",
          "description": "Alibaba Bailian model"
        },
        "vscode-git-commit-message-generator.providers.aliyun.apiKey": {
          "type": "string",
          "default": "",
          "description": "Alibaba Bailian API key"
        },
        "vscode-git-commit-message-generator.providers.openai.url": {
          "type": "string",
          "default": "https://api.openai.com/v1/chat/completions",
          "description": "OpenAI API URL"
        },
        "vscode-git-commit-message-generator.providers.openai.model": {
          "type": "string",
          "enum": [
            "gpt-5.2",
            "gpt-5-mini",
            "gpt-5-nano",
            "gpt-4.1",
            "gpt-4.1-nano",
            "gpt-4.1-mini",
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4",
            "gpt-4-turbo",
            "gpt-3.5-turbo",
            "chatgpt-4o-latest",
            "o4-mini",
            "o3",
            "o3-mini",
            "o1",
            "o1-pro",
            "o1-mini"
          ],
          "default": "gpt-5-mini",
          "description": "OpenAI model"
        },
        "vscode-git-commit-message-generator.providers.openai.apiKey": {
          "type": "string",
          "default": "",
          "description": "OpenAI API key"
        },
        "vscode-git-commit-message-generator.providers.ollama.url": {
          "type": "string",
          "default": "http://localhost:11434/api/generate",
          "description": "Ollama API URL"
        },
        "vscode-git-commit-message-generator.providers.ollama.model": {
          "type": "string",
          "default": "deepseek-r1:7b",
          "description": "Ollama model name"
        },
        "vscode-git-commit-message-generator.providers.ollama.apiKey": {
          "type": "string",
          "default": "",
          "description": "Ollama API key"
        },
        "vscode-git-commit-message-generator.providers.ollama.protocol": {
          "type": "string",
          "enum": [
            "openai",
            "ollama"
          ],
          "default": "ollama",
          "description": "Ollama protocol"
        },
        "vscode-git-commit-message-generator.providers.deepseek.url": {
          "type": "string",
          "default": "https://api.deepseek.com/v1/chat/completions",
          "description": "DeepSeek API URL"
        },
        "vscode-git-commit-message-generator.providers.deepseek.model": {
          "type": "string",
          "enum": [
            "deepseek-chat",
            "deepseek-reasoner"
          ],
          "default": "deepseek-chat",
          "description": "DeepSeek model"
        },
        "vscode-git-commit-message-generator.providers.deepseek.apiKey": {
          "type": "string",
          "default": "",
          "description": "DeepSeek API key"
        },
        "vscode-git-commit-message-generator.providers.anthropic.url": {
          "type": "string",
          "default": "https://api.anthropic.com/v1/messages",
          "description": "Anthropic API URL"
        },
        "vscode-git-commit-message-generator.providers.anthropic.model": {
          "type": "string",
          "enum": [
            "claude-sonnet-4-5",
            "claude-haiku-4-5",
            "claude-opus-4-5",
            "claude-3-opus",
            "claude-3-haiku",
            "claude-3-5-sonnet",
            "claude-3-5-haiku",
            "claude-3-7-sonnet",
            "claude-opus-4",
            "claude-sonnet-4",
            "claude-3-opus-20240229",
            "claude-3-haiku-20240307",
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022",
            "claude-3-7-sonnet-20250219",
            "claude-opus-4-20250514",
            "claude-sonnet-4-20250514"
          ],
          "default": "claude-sonnet-4-5",
          "description": "Anthropic model"
        },
        "vscode-git-commit-message-generator.providers.anthropic.apiKey": {
          "type": "string",
          "default": "",
          "description": "Anthropic API key"
        },
        "vscode-git-commit-message-generator.providers.tencent.url": {
          "type": "string",
          "default": "https://api.hunyuan.cloud.tencent.com/v1/chat/completions",
          "description": "Tencent Hunyuan API URL"
        },
        "vscode-git-commit-message-generator.providers.tencent.model": {
          "type": "string",
          "enum": [
            "hunyuan-2.0-thinking-20251109",
            "hunyuan-2.0-instruct-20251111",
            "hunyuan-a13b",
            "hunyuan-turbos-latest",
            "hunyuan-embedding",
            "hunyuan-pro",
            "hunyuan-standard",
            "hunyuan-lite",
            "hunyuan-standard-256k",
            "hunyuan-code",
            "hunyuan-turbo",
            "hunyuan-turbos-latest",
            "hunyuan-large",
            "hunyuan-t1-latest",
            "hunyuan-t1-20250521",
            "hunyuan-t1-20250403"
          ],
          "default": "hunyuan-2.0-instruct-20251111",
          "description": "Tencent Hunyuan model"
        },
        "vscode-git-commit-message-generator.providers.tencent.apiKey": {
          "type": "string",
          "default": "",
          "description": "Tencent Hunyuan API key"
        },
        "vscode-git-commit-message-generator.providers.siliconflow.url": {
          "type": "string",
          "default": "https://api.siliconflow.cn/v1/chat/completions",
          "description": "SiliconFlow API URL"
        },
        "vscode-git-commit-message-generator.providers.siliconflow.model": {
          "type": "string",
          "default": "THUDM/glm-4-9b-chat",
          "description": "SiliconFlow model"
        },
        "vscode-git-commit-message-generator.providers.siliconflow.apiKey": {
          "type": "string",
          "default": "",
          "description": "SiliconFlow API key"
        },
        "vscode-git-commit-message-generator.providers.volcengine.url": {
          "type": "string",
          "default": "https://ark.cn-beijing.volces.com/api/v3/chat/completions",
          "description": "Volcengine API URL"
        },
        "vscode-git-commit-message-generator.providers.volcengine.model": {
          "type": "string",
          "enum": [
            "deepseek-v3-2-251201",
            "deepseek-v3-1-terminus",
            "deepseek-v3-1-250821",
            "deepseek-v3-250324",
            "deepseek-v3-241226",
            "deepseek-r1-250120",
            "deepseek-r1-distill-qwen-32b-250120",
            "kimi-k2-thinking-251104",
            "doubao-seed-1-8-251215",
            "doubao-seed-code-preview-251028",
            "doubao-seed-1-6-lite-251015",
            "doubao-seed-1-6-flash-250828",
            "doubao-seed-1-6-vision-250815",
            "doubao-pro-32k-241215",
            "doubao-1-5-pro-256k-250115",
            "doubao-1-5-thinking-pro-m-250428",
            "doubao-1-5-thinking-pro-250415"
          ],
          "default": "deepseek-v3-2-251201",
          "description": "Volcengine model"
        },
        "vscode-git-commit-message-generator.providers.volcengine.apiKey": {
          "type": "string",
          "default": "",
          "description": "Volcengine API key"
        },
        "vscode-git-commit-message-generator.providers.custom.url": {
          "type": "string",
          "default": "",
          "description": "Custom API URL"
        },
        "vscode-git-commit-message-generator.providers.custom.model": {
          "type": "string",
          "default": "",
          "description": "Custom model"
        },
        "vscode-git-commit-message-generator.providers.custom.apiKey": {
          "type": "string",
          "default": "",
          "description": "Custom API key"
        },
        "vscode-git-commit-message-generator.providers.custom.protocol": {
          "type": "string",
          "enum": [
            "openai",
            "ollama"
          ],
          "default": "openai",
          "description": "Custom protocol"
        },
        "vscode-git-commit-message-generator.llm.prompt": {
          "type": "string",
          "default": "Generate a Git commit message from the following changes using the format <type>: <description>.\nFiles:\n${files}\nDiff:\n${diff}",
          "description": "Prompt template for generating commit messages. Supports ${files} and ${diff} variables."
        },
        "vscode-git-commit-message-generator.llm.system": {
          "type": "string",
          "default": "Use Conventional Commits format: <type>: <description> (max 72 chars). Add a blank line, then concise bullet points summarizing key changes. Keep output in English unless the user explicitly requests another language.",
          "description": "System instruction for commit message generation"
        },
        "vscode-git-commit-message-generator.llm.temperature": {
          "type": "number",
          "default": 0.7,
          "minimum": 0,
          "maximum": 1,
          "description": "Temperature parameter for LLM output; higher values produce more random results"
        },
        "vscode-git-commit-message-generator.llm.top_p": {
          "type": "number",
          "default": 0.9,
          "minimum": 0,
          "maximum": 1,
          "description": "Top-p parameter for LLM output; controls cumulative probability during sampling"
        },
        "vscode-git-commit-message-generator.llm.max_tokens": {
          "type": "number",
          "default": 2048,
          "minimum": 1,
          "maximum": 8192,
          "description": "Maximum token count for LLM output"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@eslint/js": "^9.39.2",
    "@types/mocha": "^10.0.10",
    "@types/node": "^25.2.3",
    "@types/vscode": "^1.57.0",
    "@typescript-eslint/eslint-plugin": "^8.55.0",
    "@typescript-eslint/parser": "^8.55.0",
    "eslint": "^9.39.2",
    "glob": "^7.1.7",
    "mocha": "^11.7.5",
    "ts-loader": "^9.2.2",
    "typescript": "^5.9.3",
    "vscode-test": "^1.5.2",
    "webpack": "^5.105.1",
    "webpack-cli": "^6.0.1"
  },
  "dependencies": {
    "simple-git": "^3.5.0"
  }
}
